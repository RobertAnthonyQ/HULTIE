{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-28T22:13:44.072203Z",
     "start_time": "2024-12-28T22:13:37.381669Z"
    }
   },
   "source": [
    "\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "BASE_DIR = os.getcwd()\n",
    "ENV_PATH = os.path.join(\"C:\\\\Users\\diego\\PycharmProjects\\HultieChatbot\", \".env\")\n",
    "\n",
    "load_dotenv(ENV_PATH)\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "def print_colored(text, color_code):\n",
    "    print(f\"\\033[{color_code}m{text}\\033[0m\")"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-28T22:13:53.466577Z",
     "start_time": "2024-12-28T22:13:49.904946Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "file_path=\"Bases-CAP-Innovacion-2024_-VF.pdf\"\n",
    "\n",
    "loader= PyPDFLoader(file_path)\n",
    "docs=loader.load()\n",
    "\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=800, chunk_overlap=100)\n",
    "doc_splits = text_splitter.split_documents(docs)\n",
    "\n",
    "embd = OpenAIEmbeddings()\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=doc_splits,\n",
    "    collection_name=\"rag-chroma\",\n",
    "    embedding=embd,\n",
    ")\n",
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\": 3},\n",
    ") "
   ],
   "id": "2cad9b0c73ca3393",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-28T22:14:39.830224Z",
     "start_time": "2024-12-28T22:14:38.636637Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from typing import Literal\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class RouteQuery(BaseModel):\n",
    "    datasource: Literal[\"general\", \"bases_del_concurso\",\"fechas_del_concurso\"] = Field(\n",
    "        ...,\n",
    "        description=\"Dada una pregunta, clasificala como general,bases del concurso, fechas del concurso.\",\n",
    "    )\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "structured_llm_router = llm.with_structured_output(RouteQuery)"
   ],
   "id": "a98436aad324e218",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-28T22:15:36.228876Z",
     "start_time": "2024-12-28T22:15:35.233780Z"
    }
   },
   "cell_type": "code",
   "source": [
    "system = \"\"\"Tomas el rol de un agente clasificador profesional, que a partir de la pregunta del usuario\n",
    "la clasifica como: general, bases del concurso o fechas del concurso.Clasificala como bases del concurso, cuando\n",
    "la pregunta del usuario tenga algo relacionado a las reglas,objetivo o vision del concurso, las fechas cuando te pregunte acerca\n",
    "del cronograma o cuando se va a llevar algo. Si algo no cumple con estas dos especificaciones, clasificalo como general\n",
    "\"\"\"\n",
    "\n",
    "route_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "question_router = route_prompt | structured_llm_router\n",
    "print_colored(question_router.invoke({\"question\": \"Dame el cronograma\"}),32)"
   ],
   "id": "b0e78b9e2ee14f60",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32mdatasource='fechas_del_concurso'\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-28T22:15:58.549362Z",
     "start_time": "2024-12-28T22:15:57.995186Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class GradeDocuments(BaseModel):\n",
    "    binary_score: str = Field(\n",
    "        description=\"Los documentos son relevantes para la pregunta del usuario, 'si' o 'no'\"\n",
    "    )\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "structured_llm_grader = llm.with_structured_output(GradeDocuments)"
   ],
   "id": "dd00a47640cf5837",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-28T22:17:30.632004Z",
     "start_time": "2024-12-28T22:17:28.003674Z"
    }
   },
   "cell_type": "code",
   "source": [
    "system = \"\"\"\n",
    "        Eres un evaluador encargado de asignar si un documento extraido de la vectorstore es relevante para responder la pregunta del usuario\n",
    "        o no.\n",
    "        Si el documento contiene keyword(s) o significado semantico relacionado a la pregunta del usuario, calificalo como relevante. Esto \n",
    "        no debe ser un test stricto, el objetivo es simplemente filtrar retrievals erroneos. Da una puntuación binaria de 'si' o 'no' para\n",
    "        indicar si un documento es o no relevante para la pregunta del usuario\"\"\"\n",
    "\n",
    "grade_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"Retrieved document: \\n\\n {document} \\n\\n User question: {question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "retrieval_grader = grade_prompt | structured_llm_grader\n",
    "question = \"Taller general de procedimientos para ganadores\"\n",
    "docs = retriever.invoke(question)\n",
    "doc_txt = docs[0].page_content\n",
    "print(doc_txt)\n",
    "print(retrieval_grader.invoke({\"question\": question, \"document\": doc_txt}))"
   ],
   "id": "d1d9bb4a20944966",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 \n",
      " \n",
      " \n",
      "10.   Otras consideraciones \n",
      " \n",
      "La Universidad se reserva el derecho de revocar la postulación o la ejecución del proyecto, según \n",
      "corresponda, cuando haya culminado el vínculo laboral o c ontractual del docente líder de l \n",
      "proyecto. De igual manera, en los casos en los que el docente líd er del proyecto registre una \n",
      "sanción como resultado de un procedimiento disciplinario contra él, en los últimos dos años, a \n",
      "través de las instancias competentes de la Universidad.  \n",
      " \n",
      "Las circunstancias no descritas en las presentes bases serán resueltas por  el vicerrector de \n",
      "investigación y el director de la DFI con la asesoría que consideren pertinentes. \n",
      " \n",
      "11.  Cronograma de postulación \n",
      " \n",
      " \n",
      "El cronograma de postulación es el siguiente: \n",
      " \n",
      " Inicio Fin \n",
      "Publicación de las bases 07/03/2024 \n",
      "Registro de propuestas 01/04/2024 29/04/2024 \n",
      "Publicación de resultados 31/07/2024 \n",
      "Taller general de procedimientos para ganadores 06/08/2024 \n",
      "Planificación operativa \n",
      " \n",
      "08/08/2024 09/09/2024 \n",
      "Generación y firma de acuerdos de subvención 08/08/2024 09/09/2024 \n",
      "Inicio de ejecución de proyectos Agosto Setiembre \n",
      " \n",
      " \n",
      "En caso no cumplan con el inicio de ejecución de los proyectos en la fecha estipulada, los \n",
      "ganadores del concurso no tendrán acceso a la subvención. \n",
      " \n",
      "Para más información u orientación sobre las presentes bases, comunicarse a:  \n",
      " \n",
      "Área de Promoción y Selección  \n",
      "Dirección de Fomento de la Investigación  \n",
      "Vicerrectorado de Investigación \n",
      "Correo electrónico: convocatorias.dfi@pucp.edu.pe  \n",
      "Teléfonos: 958198843\n",
      "binary_score='si'\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-28T22:19:13.579008Z",
     "start_time": "2024-12-28T22:19:10.877856Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"\n",
    "            Eres un asistente que responde dudas. Apartir de información sacada del vector store, responde la pregunta del usuario. Si no sabes la respuesta,\n",
    "            di explicitamente que no tienes esa información. Se conciso en tus respuesta, que no pasen las 4 oraciones.\n",
    "            Pregunta del usuario: {question}\n",
    "            Contexto (Información sacada del vector store):{context}\n",
    "            Respuesta:\n",
    "            \"\"\"\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)\n",
    "\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "rag_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "\n",
    "generation = rag_chain.invoke({\"context\": docs, \"question\": question})\n",
    "print_colored(generation,33)"
   ],
   "id": "11309a56b7a6bc44",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[33mEl Taller General de Procedimientos para Ganadores está programado para el 6 de agosto de 2024. Este taller es parte del cronograma de postulación relacionado con los proyectos ganadores. Si necesitas más información sobre el taller o el proceso, puedes comunicarte con el Área de Promoción y Selección de la Dirección de Fomento de la Investigación.\u001B[0m\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-28T22:20:35.520320Z",
     "start_time": "2024-12-28T22:20:33.965072Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "class GradeHallucinations(BaseModel):\n",
    "    binary_score: str = Field(\n",
    "        description=\"La respuesta se basa en las fuentes: si o no\"\n",
    "    )\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "structured_llm_grader = llm.with_structured_output(GradeHallucinations)\n",
    "system = \"\"\"Eres un evaluador que clasifica si una generación de un llm esta basada en la información veridica entregada de las fuentes.\n",
    "            Tu clasificación es binaria, debes clasificarlo como 'si', si es que si esta basada en la información entregada o 'no' si es que\n",
    "            se esta inventando información o no sigue la información de las fuentes. Si la información veridica entregada dice: 'No hay información' significa que no se ha encontrado información verídica relevante, asi que en ese caso, clasificalo como 'si', si la respuesta del agente refleja desconocimiento. Por otro lado, clasificalo como 'no' si es que se inventa una respuesta.\"\"\"\n",
    "hallucination_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"Información entregada por las fuentes: \\n\\n {documents} \\n\\n Generación de LLM: {generation}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "hallucination_grader = hallucination_prompt | structured_llm_grader\n",
    "hallucination_grader.invoke({\"documents\": docs, \"generation\": generation})"
   ],
   "id": "b64b56f48503a31f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradeHallucinations(binary_score='si')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-28T22:21:39.169133Z",
     "start_time": "2024-12-28T22:21:37.839215Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class GradeAnswer(BaseModel):\n",
    "    binary_score: str = Field(\n",
    "        description=\"La respuesta esta relacionada a la pregunta: si o no\"\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "structured_llm_grader = llm.with_structured_output(GradeAnswer)\n",
    "\n",
    "\n",
    "system = \"\"\" Eres un evaluador que clasifica si la respuesta que genero un llm esta relacionada a la pregunta del usuario o si la resuelve.\n",
    "            Clasifica de manera binaria con 'si' o 'no'. Donde 'si' significa que la pregunta del usuario ha sido resuelta o esta relacionada.\"\"\"\n",
    "answer_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\"human\", \"User question: \\n\\n {question} \\n\\n LLM generation: {generation}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "answer_grader = answer_prompt | structured_llm_grader\n",
    "answer_grader.invoke({\"question\": question, \"generation\": generation})"
   ],
   "id": "6d99a1df3d120bac",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradeAnswer(binary_score='si')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-28T22:21:44.981547Z",
     "start_time": "2024-12-28T22:21:43.295763Z"
    }
   },
   "cell_type": "code",
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
    "system = \"\"\"Eres un re-escritor de preguntas del usuario, convirtiendolas en una mejor versión optimizada para 'vectorstore retrieval'.\n",
    "            Analiza la pregunta y trata de razonar acerca de intento semantico de la pregunta. Siempre en español.\"\"\"\n",
    "re_write_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"Pregunta inicial: \\n\\n {question} \\n Formula una mejor version.\",\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_rewriter = re_write_prompt | llm | StrOutputParser()\n",
    "question_rewriter.invoke({\"question\": question})"
   ],
   "id": "3ed5678b7766e2da",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Versión optimizada: \\n\\n\"¿Cuáles son los procedimientos generales que se enseñan en el taller para los ganadores?\"'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-28T20:20:53.177525Z",
     "start_time": "2024-12-28T20:20:52.956507Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "web_search_tool = TavilySearchResults(k=3)"
   ],
   "id": "f927ef1c96c18ed9",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-28T22:22:10.371843Z",
     "start_time": "2024-12-28T22:22:10.222802Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#Grafoo\n",
    "from typing import List\n",
    "from langgraph.graph import END, StateGraph, START\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    question: str #Pregunta del usuariooo\n",
    "    generation: str #Respuesta del modelo\n",
    "    documents: List[str] #Lista de documentos\n",
    "    tries_retrieving: int "
   ],
   "id": "3dc2599c6f219065",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-28T22:22:48.687344Z",
     "start_time": "2024-12-28T22:22:48.666751Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.schema import Document\n",
    "\n",
    "def init(state):\n",
    "    return {\"tries_retrieving\": 0}\n",
    "\n",
    "\n",
    "def retrieve(state):\n",
    "    print_colored(\"---RETRIEVE---\",33)\n",
    "    question = state[\"question\"]\n",
    "    documents = retriever.invoke(question)\n",
    "    return {\"documents\": documents, \"question\": question}\n",
    "\n",
    "\n",
    "def generate(state):\n",
    "    print_colored(\"---LLM:GENERACION---\",32)\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    generation = rag_chain.invoke({\"context\": documents, \"question\": question})\n",
    "    return {\"documents\": documents, \"question\": question, \"generation\": generation}\n",
    "\n",
    "\n",
    "def grade_documents(state):\n",
    "    \n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    tries = state[\"tries_retrieving\"]\n",
    "    print_colored(f\"---VERIFICANDO RELAVANCIA DE INFORMACIÓN---INTENTO:{tries}\",35)\n",
    "    filtered_docs = []\n",
    "    if tries < 3:\n",
    "        for d in documents:\n",
    "            score = retrieval_grader.invoke(\n",
    "                {\"question\": question, \"document\": d.page_content}\n",
    "            )\n",
    "            grade = score.binary_score\n",
    "            if grade == \"si\":\n",
    "                print_colored(\"---DOCUMENTO RELEVANTE---\",34)\n",
    "                filtered_docs.append(d)\n",
    "            else:\n",
    "                print(\"---DOCUMENT NO RELEVANTE---\",31)\n",
    "                continue\n",
    "    else:\n",
    "        filtered_docs.append(\"Sin informacion\")\n",
    "    return {\"tries_retrieving\":tries+1,\"documents\": filtered_docs, \"question\": question}\n",
    "\n",
    "\n",
    "def transform_query(state):\n",
    "    \n",
    "    print_colored(\"---TRANSFORMAR PREGUNTA A UNA VERSION OPTIMIZADA PARA VECTORSTORE---\",32)\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    better_question = question_rewriter.invoke({\"question\": question})\n",
    "    return {\"documents\": documents, \"question\": better_question}\n",
    "\n",
    "\n",
    "def general(state):\n",
    "    print_colored(\"---LLM:GENERACION---\",32)\n",
    "    question = state[\"question\"]\n",
    "    generation = rag_chain.invoke({\"context\": \"Información general, responder la pregunta de manera conscisa y si no tiene nada que ver con el concurso,redirigirlo\", \"question\": question})\n",
    "    return {\"question\": question, \"generation\": generation}\n",
    "\n",
    "\n",
    "def route_question(state):\n",
    "    print_colored(\"---CLASIFICACIÓN DE PREGUNTA---\",36)\n",
    "    question = state[\"question\"]\n",
    "    source = question_router.invoke({\"question\": question})\n",
    "    if source.datasource == \"bases_del_concurso\":\n",
    "        print_colored(\"---PREGUNTA CLASIFICADA COMO: bases_del_concurso---\",36)\n",
    "        return \"vectorstore\"\n",
    "    elif source.datasource == \"fechas_del_concurso\":\n",
    "        print_colored(\"---PREGUNTA CLASIFICADA COMO: fechas_del_concurso---\",36)\n",
    "        return \"vectorstore\"\n",
    "    elif source.datasource == \"general\":\n",
    "        print_colored(\"---PREGUNTA CLASIFICADA COMO: general---\",36)\n",
    "        return \"general\"\n",
    "\n",
    "\n",
    "def decide_to_generate(state):\n",
    "\n",
    "    print(\"---ASSESS GRADED DOCUMENTS---\")\n",
    "    state[\"question\"]\n",
    "    filtered_documents = state[\"documents\"]\n",
    "\n",
    "    if not filtered_documents:\n",
    "        print_colored(\n",
    "            \"---NINGÚN DOCUMENTO ES RELEVANTE PARA RESPONDER LA PREGUNTA---\",31\n",
    "        )\n",
    "        return \"transform_query\"\n",
    "    else:\n",
    "        # We have relevant documents, so generate answer\n",
    "        print_colored(\"---HAY DOCUMENTOS RELEVANTES, GENERANDO...---\",32)\n",
    "        return \"generate\"\n",
    "\n",
    "\n",
    "def grade_generation_v_documents_and_question(state):\n",
    "    print_colored(\"---VERIFICANDO ALUCINACIONES---\",33)\n",
    "    question = state[\"question\"]\n",
    "    documents = state[\"documents\"]\n",
    "    generation = state[\"generation\"]\n",
    "\n",
    "    score = hallucination_grader.invoke(\n",
    "        {\"documents\": documents, \"generation\": generation}\n",
    "    )\n",
    "    \n",
    "    print_colored(f\"generacion:{generation}-\",33)\n",
    "    print_colored(f\"documentos:{documents}\",33)\n",
    "    grade = score.binary_score\n",
    "    if grade == \"si\":\n",
    "        print_colored(\"---NO HAY ALUCINACIONES---\",33)\n",
    "        return \"useful\"\n",
    "    else:\n",
    "        print_colored(\"---EXISTEN ALUCIONACIONES, REINTENTANDO---\",31)\n",
    "        return \"not supported\""
   ],
   "id": "21543283894f29e1",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-28T22:25:29.529300Z",
     "start_time": "2024-12-28T22:25:29.522531Z"
    }
   },
   "cell_type": "code",
   "source": [
    "workflow = StateGraph(GraphState)\n",
    "workflow.add_node(\"init\",init)\n",
    "workflow.add_node(\"general\", general)  \n",
    "workflow.add_node(\"retrieve\", retrieve)  \n",
    "workflow.add_node(\"grade_documents\", grade_documents) \n",
    "workflow.add_node(\"generate\", generate)  \n",
    "workflow.add_node(\"transform_query\", transform_query)  \n",
    "workflow.add_edge(START,\"init\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"init\",\n",
    "    route_question,\n",
    "    {\n",
    "        \"general\": \"general\",\n",
    "        \"vectorstore\": \"retrieve\",\n",
    "    },\n",
    ")\n",
    "workflow.add_edge(\"general\",END)\n",
    "workflow.add_edge(\"retrieve\", \"grade_documents\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"grade_documents\",\n",
    "    decide_to_generate,\n",
    "    {\n",
    "        \"transform_query\": \"transform_query\",\n",
    "        \"generate\": \"generate\",\n",
    "    },\n",
    ")\n",
    "workflow.add_edge(\"transform_query\", \"retrieve\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"generate\",\n",
    "    grade_generation_v_documents_and_question,\n",
    "    {\n",
    "        \"not supported\": \"generate\",\n",
    "        \"useful\": END,\n",
    "    },\n",
    ")\n",
    "app = workflow.compile()"
   ],
   "id": "b30541304d503790",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-28T22:28:28.833012Z",
     "start_time": "2024-12-28T22:28:22.730493Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pprint import pprint\n",
    "\n",
    "inputs = {\n",
    "    \"question\": \"Que visión tiene el concurso?\"\n",
    "}\n",
    "for output in app.stream(inputs):\n",
    "    for key, value in output.items():\n",
    "        pprint(f\"Node '{key}':\")\n",
    "    pprint(\"\\n---\\n\")\n",
    "pprint(value[\"generation\"])"
   ],
   "id": "c3163fe1039fd86a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36m---CLASIFICACIÓN DE PREGUNTA---\u001B[0m\n",
      "\u001B[36m---PREGUNTA CLASIFICADA COMO: bases_del_concurso---\u001B[0m\n",
      "\"Node 'init':\"\n",
      "'\\n---\\n'\n",
      "\u001B[33m---RETRIEVE---\u001B[0m\n",
      "\"Node 'retrieve':\"\n",
      "'\\n---\\n'\n",
      "\u001B[35m---VERIFICANDO RELAVANCIA DE INFORMACIÓN---INTENTO:0\u001B[0m\n",
      "---DOCUMENT NO RELEVANTE--- 31\n",
      "\u001B[34m---DOCUMENTO RELEVANTE---\u001B[0m\n",
      "---DOCUMENT NO RELEVANTE--- 31\n",
      "---ASSESS GRADED DOCUMENTS---\n",
      "\u001B[32m---HAY DOCUMENTOS RELEVANTES, GENERANDO...---\u001B[0m\n",
      "\"Node 'grade_documents':\"\n",
      "'\\n---\\n'\n",
      "\u001B[32m---LLM:GENERACION---\u001B[0m\n",
      "\u001B[33m---VERIFICANDO ALUCINACIONES---\u001B[0m\n",
      "\u001B[33mgeneracion:La visión del concurso es dinamizar el ecosistema de innovación de la PUCP, promoviendo la generación de iniciativas de innovación y maduración tecnológica. Se busca fomentar una cultura de innovación y desarrollar capacidades que amplíen la comunidad de innovadores y emprendedores en la universidad. Además, se pretende que los proyectos tengan un impacto positivo en la sociedad y contribuyan al desarrollo interdisciplinario.-\u001B[0m\n",
      "\u001B[33mdocumentos:[Document(metadata={'page': 0, 'source': 'Bases-CAP-Innovacion-2024_-VF.pdf'}, page_content='1 \\nConcurso Anual de Proyectos de Innovación PUCP 2024 \\nIV Convocatoria \\n \\n \\n1. Objetivo del concurso \\n \\nEl Concurso Anual de Proyectos de Innovación (CAP  Innovación) 2024, organizado por el \\nVicerrectorado de Investigación de la Pontificia Universidad Católica del Pe rú (PUCP), busca \\ndinamizar el ecosistema de innovación de la Universidad, mediante la generación de iniciativas \\nde innovación y maduración tecnológica de resultados de proyectos I+D+i. Este concurso se \\nencuentra alineado a la estrategia número 9 del objeti vo 3 del Plan Estratégico Institucional \\n2023-2027: “Fomentar una cultura de innovación y contar con una estrategia de estímulos para \\nel desarrollo de capacidades que permitan ampliar la comunidad de innovadores y emprendedores \\nen la Universidad.” \\n \\nObjetivo del concurso \\n \\nObjetivo General: Promover el desarrollo de proyectos de innovación en docentes PUCP para \\nque realicen soluciones que tengan un impacto positivo en la sociedad , aporten al desarrollo \\ninterdisciplinario, y propicien la transferencia de conocimientos a la sociedad. \\n \\nObjetivos Específicos: \\n• Potenciar el ecosistema de innovación PUCP. \\n• Incrementar el valor e impacto de las tecnologías desarrolladas en la PUCP. \\n• Vincular los actores y desafíos de la sociedad con los actores del ecosistema PUCP. \\n \\nLos proyectos postulados deben cumplir con estos objetivos y con los términos planteados en \\nlas definiciones de innovación por lo que se reserva el derecho a revisión de aquellos proyectos \\nque no tengan relación con estos términos. Los proyectos postulados deben  enfocarse en \\nentender y/o resolver un desafío actual de nuestra sociedad desde una perspectiva \\ninterdisciplinaria. A continuación, se detallan las definiciones de los conceptos de tecnología, \\ninnovación y prototipo. \\n \\nTecnología: Según Gay (1997) se define  la tecnología como , “un conjunto ordenado de \\nconocimientos, y los correspondientes procesos, que tienen como objetivo la producción de \\nbienes y servicios, teniendo en cuenta la técnica, la ciencia y los aspectos económicos, sociales y')]\u001B[0m\n",
      "\u001B[33m---NO HAY ALUCINACIONES---\u001B[0m\n",
      "\"Node 'generate':\"\n",
      "'\\n---\\n'\n",
      "('La visión del concurso es dinamizar el ecosistema de innovación de la PUCP, '\n",
      " 'promoviendo la generación de iniciativas de innovación y maduración '\n",
      " 'tecnológica. Se busca fomentar una cultura de innovación y desarrollar '\n",
      " 'capacidades que amplíen la comunidad de innovadores y emprendedores en la '\n",
      " 'universidad. Además, se pretende que los proyectos tengan un impacto '\n",
      " 'positivo en la sociedad y contribuyan al desarrollo interdisciplinario.')\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "9a8682423ae41ed1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "b59dd8f60df2615d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
